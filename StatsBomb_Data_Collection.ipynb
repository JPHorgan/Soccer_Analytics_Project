{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the cloned open-data\n",
    "Assuming you have cloned the open-data using git you can also get a list of files with glob.\n",
    "If you are not using git, comment this out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the path of STATSBOMB_DATA to the location of you open-data\n",
    "# STATSBOMB_DATA = os.path.join('..', '..', '..', 'open-data','data')\n",
    "# event_links = glob.glob(os.path.join(STATSBOMB_DATA, 'events', '**', '*.json'),recursive=True)\n",
    "# lineup_links = glob.glob(os.path.join(STATSBOMB_DATA, 'lineups', '**', '*.json'),recursive=True)\n",
    "# match_links = glob.glob(os.path.join(STATSBOMB_DATA, 'matches', '**', '*.json'),recursive=True)\n",
    "# COMPETITION_PATH = os.path.join(STATSBOMB_DATA, 'competitions.json')\n",
    "\n",
    "# print('Number of event files:',len(event_links))\n",
    "# print('Number of lineup files:', len(lineup_links))\n",
    "# print('Number of match files:', len(match_links))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup some destination folders\n",
    "Now we need to setup some folders to store the dataframes.\n",
    "We are going to setup the following directory structure\n",
    "\n",
    "| data <- top level directory to store the combined dataframes\n",
    "| ├── event_raw <- Folder for event data\n",
    "| ├── related_raw <- Folder for info on how events are connected\n",
    "| ├── freeze_raw <- Folder for the individual shot freeze frames\n",
    "| ├── tactic_raw <-Folder for the lineup tactics\n",
    "| ├── lineup_raw <- Folder for the lineup info\n",
    "\n",
    "I am saving the dataframes as parquet files as they are small and load rapidly\n",
    "(see here for more info https://ursalabs.org/blog/2019-10-columnar-perf/).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amend this path to where you want to store the data\n",
    "DATA_FOLDER = os.path.join(r'C:\\........')\n",
    "\n",
    "# make the directory structure\n",
    "for folder in ['event_raw', 'related_raw', 'freeze_raw', 'tactic_raw', 'lineup_raw']:\n",
    "    path = os.path.join(DATA_FOLDER, folder)\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Competition data\n",
    "Get the competition data as a dataframe as save as parquet file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37 entries, 0 to 36\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   competition_id      37 non-null     int64         \n",
      " 1   season_id           37 non-null     int64         \n",
      " 2   country_name        37 non-null     object        \n",
      " 3   competition_name    37 non-null     object        \n",
      " 4   competition_gender  37 non-null     object        \n",
      " 5   season_name         37 non-null     object        \n",
      " 6   match_updated       37 non-null     datetime64[ns]\n",
      " 7   match_available     37 non-null     datetime64[ns]\n",
      "dtypes: datetime64[ns](2), int64(2), object(4)\n",
      "memory usage: 2.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_competition = sbapi.read_competition(COMPETITION_PATH, warn=False)\n",
    "# note there is a slight loss of data quality with timestamps,\n",
    "# but these aren't relevant for analysis\n",
    "# pandas has nanoseconds, which aren't supported in parquet (supports milliseconds)\n",
    "df_competition.to_parquet(os.path.join(DATA_FOLDER, 'competition.parquet'),\n",
    "                          allow_truncated_timestamps=True)\n",
    "df_competition.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep a copy of the old match data\n",
    "We are going to use this to compare to the new match file and check for updates.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_path = os.path.join(DATA_FOLDER, 'match.parquet')\n",
    "if os.path.exists(match_path):\n",
    "    df_match_copy = pd.read_parquet(match_path).copy()\n",
    "    UPDATE_FILES = True\n",
    "else:\n",
    "    UPDATE_FILES = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match data\n",
    "Get the match data as a dataframe and save as parquet.\n",
    "Note there is a mismatch between the length of this file\n",
    "and the number of event files because some event files don't have match data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>match_date</th>\n",
       "      <th>kick_off</th>\n",
       "      <th>home_score</th>\n",
       "      <th>away_score</th>\n",
       "      <th>match_status_360</th>\n",
       "      <th>last_updated</th>\n",
       "      <th>last_updated_360</th>\n",
       "      <th>match_week</th>\n",
       "      <th>competition_id</th>\n",
       "      <th>...</th>\n",
       "      <th>home_team_managers_dob</th>\n",
       "      <th>home_team_managers_country_id</th>\n",
       "      <th>home_team_managers_country_name</th>\n",
       "      <th>away_team_managers_id</th>\n",
       "      <th>away_team_managers_name</th>\n",
       "      <th>away_team_managers_nickname</th>\n",
       "      <th>away_team_managers_dob</th>\n",
       "      <th>away_team_managers_country_id</th>\n",
       "      <th>away_team_managers_country_name</th>\n",
       "      <th>metadata_xy_fidelity_version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7430</td>\n",
       "      <td>2018-04-15</td>\n",
       "      <td>2018-04-15 01:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>unscheduled</td>\n",
       "      <td>2020-07-29 05:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>...</td>\n",
       "      <td>1959-09-22</td>\n",
       "      <td>241.0</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>127.0</td>\n",
       "      <td>Paul Riley</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>68.0</td>\n",
       "      <td>England</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7443</td>\n",
       "      <td>2018-05-05</td>\n",
       "      <td>2018-05-05 21:30:00</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>unscheduled</td>\n",
       "      <td>2020-07-29 05:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>49</td>\n",
       "      <td>...</td>\n",
       "      <td>1986-08-08</td>\n",
       "      <td>241.0</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>141.0</td>\n",
       "      <td>Vlatko Andonovski</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>241.0</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7444</td>\n",
       "      <td>2018-05-06</td>\n",
       "      <td>2018-05-06 21:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>unscheduled</td>\n",
       "      <td>2020-07-29 05:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>49</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>68.0</td>\n",
       "      <td>England</td>\n",
       "      <td>142.0</td>\n",
       "      <td>Rory Dames</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>241.0</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7445</td>\n",
       "      <td>2018-05-06</td>\n",
       "      <td>2018-05-06 03:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>unscheduled</td>\n",
       "      <td>2020-07-29 05:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>49</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>68.0</td>\n",
       "      <td>England</td>\n",
       "      <td>131.0</td>\n",
       "      <td>James Gabarra</td>\n",
       "      <td>None</td>\n",
       "      <td>1959-09-22</td>\n",
       "      <td>241.0</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7451</td>\n",
       "      <td>2018-05-13</td>\n",
       "      <td>2018-05-13 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>unscheduled</td>\n",
       "      <td>2020-07-29 05:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>49</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>68.0</td>\n",
       "      <td>England</td>\n",
       "      <td>131.0</td>\n",
       "      <td>James Gabarra</td>\n",
       "      <td>None</td>\n",
       "      <td>1959-09-22</td>\n",
       "      <td>241.0</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   match_id match_date            kick_off  home_score  away_score  \\\n",
       "0      7430 2018-04-15 2018-04-15 01:00:00           2           4   \n",
       "1      7443 2018-05-05 2018-05-05 21:30:00           2           3   \n",
       "3      7444 2018-05-06 2018-05-06 21:00:00           1           1   \n",
       "2      7445 2018-05-06 2018-05-06 03:00:00           2           0   \n",
       "4      7451 2018-05-13 2018-05-13 01:00:00           1           0   \n",
       "\n",
       "  match_status_360        last_updated  last_updated_360  match_week  \\\n",
       "0      unscheduled 2020-07-29 05:00:00               NaN           3   \n",
       "1      unscheduled 2020-07-29 05:00:00               NaN           6   \n",
       "3      unscheduled 2020-07-29 05:00:00               NaN           6   \n",
       "2      unscheduled 2020-07-29 05:00:00               NaN           6   \n",
       "4      unscheduled 2020-07-29 05:00:00               NaN           7   \n",
       "\n",
       "   competition_id  ... home_team_managers_dob home_team_managers_country_id  \\\n",
       "0              49  ...             1959-09-22                         241.0   \n",
       "1              49  ...             1986-08-08                         241.0   \n",
       "3              49  ...                    NaT                          68.0   \n",
       "2              49  ...                    NaT                          68.0   \n",
       "4              49  ...                    NaT                          68.0   \n",
       "\n",
       "   home_team_managers_country_name away_team_managers_id  \\\n",
       "0         United States of America                 127.0   \n",
       "1         United States of America                 141.0   \n",
       "3                          England                 142.0   \n",
       "2                          England                 131.0   \n",
       "4                          England                 131.0   \n",
       "\n",
       "   away_team_managers_name away_team_managers_nickname away_team_managers_dob  \\\n",
       "0               Paul Riley                        None                    NaT   \n",
       "1        Vlatko Andonovski                        None                    NaT   \n",
       "3               Rory Dames                        None                    NaT   \n",
       "2            James Gabarra                        None             1959-09-22   \n",
       "4            James Gabarra                        None             1959-09-22   \n",
       "\n",
       "  away_team_managers_country_id  away_team_managers_country_name  \\\n",
       "0                          68.0                          England   \n",
       "1                         241.0         United States of America   \n",
       "3                         241.0         United States of America   \n",
       "2                         241.0         United States of America   \n",
       "4                         241.0         United States of America   \n",
       "\n",
       "  metadata_xy_fidelity_version  \n",
       "0                          NaN  \n",
       "1                          NaN  \n",
       "3                          NaN  \n",
       "2                          NaN  \n",
       "4                          NaN  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_match.sort_values('match_id').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping https://raw.githubusercontent.com/statsbomb/open-data/master/data/matches/16/42.json: empty json\n",
      "Skipping https://raw.githubusercontent.com/statsbomb/open-data/master/data/matches/16/76.json: empty json\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 879 entries, 0 to 51\n",
      "Data columns (total 50 columns):\n",
      " #   Column                           Non-Null Count  Dtype         \n",
      "---  ------                           --------------  -----         \n",
      " 0   match_id                         879 non-null    int64         \n",
      " 1   match_date                       879 non-null    datetime64[ns]\n",
      " 2   kick_off                         877 non-null    datetime64[ns]\n",
      " 3   home_score                       879 non-null    int64         \n",
      " 4   away_score                       879 non-null    int64         \n",
      " 5   match_status_360                 878 non-null    object        \n",
      " 6   last_updated                     879 non-null    datetime64[ns]\n",
      " 7   last_updated_360                 0 non-null      float64       \n",
      " 8   match_week                       879 non-null    int64         \n",
      " 9   competition_id                   879 non-null    int64         \n",
      " 10  competition_country_name         879 non-null    object        \n",
      " 11  competition_name                 879 non-null    object        \n",
      " 12  season_id                        879 non-null    int64         \n",
      " 13  season_name                      879 non-null    object        \n",
      " 14  home_team_id                     879 non-null    int64         \n",
      " 15  home_team_name                   879 non-null    object        \n",
      " 16  competition_gender               879 non-null    object        \n",
      " 17  home_team_group                  92 non-null     object        \n",
      " 18  home_team_country_id             879 non-null    int64         \n",
      " 19  home_team_country_name           879 non-null    object        \n",
      " 20  away_team_id                     879 non-null    int64         \n",
      " 21  away_team_name                   879 non-null    object        \n",
      " 22  away_team_group                  92 non-null     object        \n",
      " 23  away_team_country_id             879 non-null    int64         \n",
      " 24  away_team_country_name           879 non-null    object        \n",
      " 25  metadata_data_version            879 non-null    object        \n",
      " 26  metadata_shot_fidelity_version   684 non-null    object        \n",
      " 27  competition_stage_id             879 non-null    int64         \n",
      " 28  competition_stage_name           879 non-null    object        \n",
      " 29  stadium_id                       796 non-null    float64       \n",
      " 30  stadium_name                     796 non-null    object        \n",
      " 31  stadium_country_id               796 non-null    float64       \n",
      " 32  stadium_country_name             796 non-null    object        \n",
      " 33  referee_id                       813 non-null    float64       \n",
      " 34  referee_name                     813 non-null    object        \n",
      " 35  referee_country_id               510 non-null    float64       \n",
      " 36  referee_country_name             510 non-null    object        \n",
      " 37  home_team_managers_id            795 non-null    float64       \n",
      " 38  home_team_managers_name          795 non-null    object        \n",
      " 39  home_team_managers_nickname      438 non-null    object        \n",
      " 40  home_team_managers_dob           81 non-null     datetime64[ns]\n",
      " 41  home_team_managers_country_id    795 non-null    float64       \n",
      " 42  home_team_managers_country_name  795 non-null    object        \n",
      " 43  away_team_managers_id            795 non-null    float64       \n",
      " 44  away_team_managers_name          795 non-null    object        \n",
      " 45  away_team_managers_nickname      445 non-null    object        \n",
      " 46  away_team_managers_dob           84 non-null     datetime64[ns]\n",
      " 47  away_team_managers_country_id    795 non-null    float64       \n",
      " 48  away_team_managers_country_name  795 non-null    object        \n",
      " 49  metadata_xy_fidelity_version     594 non-null    object        \n",
      "dtypes: datetime64[ns](5), float64(9), int64(11), object(25)\n",
      "memory usage: 350.2+ KB\n"
     ]
    }
   ],
   "source": [
    "match_dfs = [sbapi.read_match(file, warn=False) for file in match_links]\n",
    "df_match = pd.concat(match_dfs)\n",
    "# again there is a slight loss of quality when saving timestamps, but only relevant for last_updated\n",
    "df_match.to_parquet(os.path.join(DATA_FOLDER, 'match.parquet'),\n",
    "                    allow_truncated_timestamps=True)\n",
    "df_match.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a list of games which have been updated\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if UPDATE_FILES:\n",
    "    df_match_copy = (df_match[['match_id', 'last_updated']]\n",
    "                     .merge(df_match_copy[['match_id', 'last_updated']],\n",
    "                            how='left', suffixes=['', '_old'], on='match_id'))\n",
    "    df_match_copy = df_match_copy[(df_match_copy.last_updated.dt.floor('ms') !=\n",
    "                                   df_match_copy.last_updated_old.dt.floor('ms'))].copy()\n",
    "    to_update = df_match_copy.match_id.unique()\n",
    "\n",
    "    # get array of event links to update - based on whether they have been updated in the match json\n",
    "    event_link_ids = [int(os.path.splitext(os.path.basename(link))[0]) for link in event_links]\n",
    "    event_to_update = [link in to_update for link in event_link_ids]\n",
    "    event_links = np.array(event_links)[event_to_update]\n",
    "\n",
    "    # get array of lineup links to update -\n",
    "    # based on whether they have been updated in the match jsons\n",
    "    lineup_link_ids = [int(os.path.splitext(os.path.basename(link))[0]) for link in lineup_links]\n",
    "    lineup_to_update = [link in to_update for link in lineup_link_ids]\n",
    "    lineup_links = np.array(lineup_links)[lineup_to_update]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset a few files for demo purposes\n",
    "For the purposes of the demo, we will take the first five event and lineup files\n",
    "Comment this out if you want the whole of the open-data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineup_links = lineup_links\n",
    "event_links = event_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lineup data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b6ce93c344f47e493d1c1e75819dc6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/890 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Amend this path to where you want to store the data\n",
    "LINEUP_FOLDER = os.path.join(DATA_FOLDER, 'lineup_raw')\n",
    "# loop through all the changed links and store as parquet files - small and fast files\n",
    "for file in tqdm(lineup_links):\n",
    "    save_path = f'{os.path.basename(file)[:-4]}parquet'\n",
    "    try:\n",
    "        df_lineup = sbapi.read_lineup(file, warn=False)\n",
    "        df_lineup.to_parquet(os.path.join(LINEUP_FOLDER, save_path))\n",
    "    except ValueError:\n",
    "        print('Skipping file:', file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the lineup files as a single dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 26794 entries, 0 to 35\n",
      "Data columns (total 9 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   team_id               26794 non-null  int64 \n",
      " 1   team_name             26794 non-null  object\n",
      " 2   match_id              26794 non-null  int64 \n",
      " 3   player_id             26794 non-null  int64 \n",
      " 4   player_name           26794 non-null  object\n",
      " 5   player_nickname       14740 non-null  object\n",
      " 6   player_jersey_number  26794 non-null  int64 \n",
      " 7   player_country_id     26794 non-null  int64 \n",
      " 8   player_country_name   26794 non-null  object\n",
      "dtypes: int64(5), object(4)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "if len(lineup_links) == 0:\n",
    "    print('No update')\n",
    "else:\n",
    "    lineup_files = glob.glob(os.path.join(LINEUP_FOLDER, '*.parquet'))\n",
    "    df_lineup = pd.concat([pd.read_parquet(file) for file in lineup_files])\n",
    "    df_lineup.to_parquet(os.path.join(DATA_FOLDER, 'lineup.parquet'))\n",
    "    df_lineup.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event data\n",
    "We will also loop through the first five event files.\n",
    "However, the ``read_event`` function returns a dictionary of four dataframes:\n",
    "'event', 'related_event', 'shot_freeze_frame' and 'tactics_lineup'.\n",
    "It's possible to alter ``read_event`` to return fewer dataframes (see the API docs).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e5593015e0e48e2a48ec8b74c1bee55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/890 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loop through all the changed links and store as parquet files - small and fast files\n",
    "for file in tqdm(event_links):\n",
    "    save_path = f'{os.path.basename(file)[:-4]}parquet'\n",
    "    try:\n",
    "        dict_event = sbapi.read_event(file, warn=False)\n",
    "        # save to parquet files\n",
    "        # using the dictionary key to access the dataframes from the dictionary\n",
    "        dict_event['event'].to_parquet(os.path.join(DATA_FOLDER, 'event_raw', save_path))\n",
    "        dict_event['related_event'].to_parquet(os.path.join(DATA_FOLDER, 'related_raw', save_path))\n",
    "        dict_event['shot_freeze_frame'].to_parquet(os.path.join(DATA_FOLDER, 'freeze_raw',\n",
    "                                                                save_path))\n",
    "        dict_event['tactics_lineup'].to_parquet(os.path.join(DATA_FOLDER, 'tactic_raw', save_path))\n",
    "    except ValueError:\n",
    "        print('Skipping:', file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a list of match_ids to update\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_files = glob.glob(os.path.join(DATA_FOLDER, 'event_raw', '*.parquet'))\n",
    "if UPDATE_FILES:\n",
    "    ids_to_update = [int(os.path.splitext(os.path.basename(link))[0]) for link in event_links]\n",
    "\n",
    "\n",
    "# Function to load the old dataframe (if exists) and combine with the updated parquet files\n",
    "def update(directory, file_type, update_ids):\n",
    "    \"\"\" Update an old DataFrame with files that have changed/ been added.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    directory : path to directory containing the files\n",
    "    file_type : str\n",
    "        One of 'event', 'freeze', 'tatic', or related'\n",
    "    update_ids : list of integers\n",
    "        A list of the match ids to update\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : pandas.DataFrame\n",
    "        An updated DataFrame with the new/changed matches.\n",
    "    \"\"\"\n",
    "    # get a list of parquet files to add to the old dataframe\n",
    "    files = glob.glob(os.path.join(directory, f'{file_type}_raw', '*.parquet'))\n",
    "    files_id = [int(os.path.splitext(os.path.basename(file))[0]) for file in files]\n",
    "    mask_update = [match_id in update_ids for match_id in files_id]\n",
    "    files = np.array(files)[mask_update]\n",
    "    # load the old dataframe, filter out changed matches and add the new parquet files\n",
    "    df_old = pd.read_parquet(os.path.join(directory, f'{file_type}.parquet'))\n",
    "    df_old = df_old[~df_old.match_id.isin(update_ids)]\n",
    "    df_new = pd.concat([pd.read_parquet(file) for file in files])\n",
    "    df_old = pd.concat([df_old, df_new])\n",
    "    return df_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get event files as a single dataframe and save to parquet.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-39-4223d548f176>:11: FutureWarning: null_counts is deprecated. Use show_counts instead\n",
      "  df_event.info(verbose=True, null_counts=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3198449 entries, 0 to 3746\n",
      "Data columns (total 95 columns):\n",
      " #   Column                          Non-Null Count    Dtype  \n",
      "---  ------                          --------------    -----  \n",
      " 0   match_id                        3198449 non-null  int64  \n",
      " 1   id                              3198449 non-null  object \n",
      " 2   index                           3198449 non-null  int64  \n",
      " 3   period                          3198449 non-null  int64  \n",
      " 4   timestamp_minute                3198449 non-null  int64  \n",
      " 5   timestamp_second                3198449 non-null  int64  \n",
      " 6   timestamp_millisecond           3198449 non-null  int64  \n",
      " 7   minute                          3198449 non-null  int64  \n",
      " 8   second                          3198449 non-null  int64  \n",
      " 9   type_id                         3198449 non-null  int64  \n",
      " 10  type_name                       3198449 non-null  object \n",
      " 11  sub_type_id                     280209 non-null   float64\n",
      " 12  sub_type_name                   280209 non-null   object \n",
      " 13  outcome_id                      444328 non-null   float64\n",
      " 14  outcome_name                    444328 non-null   object \n",
      " 15  play_pattern_id                 3198449 non-null  int64  \n",
      " 16  play_pattern_name               3198449 non-null  object \n",
      " 17  possession_team_id              3198449 non-null  int64  \n",
      " 18  possession                      3198449 non-null  int64  \n",
      " 19  possession_team_name            3198449 non-null  object \n",
      " 20  team_id                         3198449 non-null  int64  \n",
      " 21  team_name                       3198449 non-null  object \n",
      " 22  player_id                       3181705 non-null  float64\n",
      " 23  player_name                     3181705 non-null  object \n",
      " 24  position_id                     3181705 non-null  float64\n",
      " 25  position_name                   3181705 non-null  object \n",
      " 26  duration                        2343493 non-null  float64\n",
      " 27  x                               3173431 non-null  float64\n",
      " 28  y                               3173431 non-null  float64\n",
      " 29  z                               0 non-null        float64\n",
      " 30  end_x                           1645237 non-null  float64\n",
      " 31  end_y                           1645237 non-null  float64\n",
      " 32  end_z                           16408 non-null    float64\n",
      " 33  body_part_id                    890613 non-null   float64\n",
      " 34  body_part_name                  890613 non-null   object \n",
      " 35  technique_id                    41904 non-null    float64\n",
      " 36  technique_name                  41908 non-null    object \n",
      " 37  counterpress                    99100 non-null    float64\n",
      " 38  under_pressure                  689474 non-null   float64\n",
      " 39  pass_length                     882536 non-null   float64\n",
      " 40  pass_angle                      882536 non-null   float64\n",
      " 41  pass_recipient_id               819707 non-null   float64\n",
      " 42  pass_recipient_name             819707 non-null   object \n",
      " 43  pass_height_id                  882536 non-null   float64\n",
      " 44  pass_height_name                882536 non-null   object \n",
      " 45  pass_switch                     23945 non-null    object \n",
      " 46  pass_assisted_shot_id           15865 non-null    object \n",
      " 47  pass_shot_assist                13993 non-null    object \n",
      " 48  pass_cross                      18936 non-null    object \n",
      " 49  pass_backheel                   949 non-null      object \n",
      " 50  pass_deflected                  1045 non-null     object \n",
      " 51  pass_cut_back                   1633 non-null     object \n",
      " 52  pass_goal_assist                1872 non-null     object \n",
      " 53  bad_behaviour_card_id           631 non-null      float64\n",
      " 54  bad_behaviour_card_name         631 non-null      object \n",
      " 55  ball_recovery_recovery_failure  7298 non-null     object \n",
      " 56  block_offensive                 506 non-null      object \n",
      " 57  block_deflection                1004 non-null     object \n",
      " 58  dribble_overrun                 2193 non-null     object \n",
      " 59  foul_committed_card_id          2820 non-null     float64\n",
      " 60  foul_committed_card_name        2820 non-null     object \n",
      " 61  foul_committed_advantage        3339 non-null     object \n",
      " 62  foul_committed_type_id          1592 non-null     float64\n",
      " 63  foul_committed_type_name        1592 non-null     object \n",
      " 64  foul_won_defensive              6263 non-null     object \n",
      " 65  foul_won_advantage              3428 non-null     object \n",
      " 66  goalkeeper_position_id          22652 non-null    float64\n",
      " 67  goalkeeper_position_name        22652 non-null    object \n",
      " 68  shot_statsbomb_xg               22672 non-null    float64\n",
      " 69  shot_key_pass_id                15865 non-null    object \n",
      " 70  shot_first_time                 6088 non-null     object \n",
      " 71  shot_one_on_one                 1413 non-null     object \n",
      " 72  substitution_replacement_id     4915 non-null     float64\n",
      " 73  substitution_replacement_name   4915 non-null     object \n",
      " 74  tactics_formation               3347 non-null     float64\n",
      " 75  aerial_won                      21289 non-null    object \n",
      " 76  ball_recovery_offensive         333 non-null      object \n",
      " 77  dribble_nutmeg                  1214 non-null     object \n",
      " 78  off_camera                      34764 non-null    object \n",
      " 79  foul_committed_penalty          266 non-null      object \n",
      " 80  foul_won_penalty                219 non-null      object \n",
      " 81  shot_redirect                   75 non-null       object \n",
      " 82  shot_deflected                  236 non-null      object \n",
      " 83  pass_miscommunication           577 non-null      object \n",
      " 84  foul_committed_offensive        1041 non-null     object \n",
      " 85  block_save_block                191 non-null      object \n",
      " 86  out                             19599 non-null    float64\n",
      " 87  shot_open_goal                  266 non-null      object \n",
      " 88  injury_stoppage_in_chain        340 non-null      object \n",
      " 89  shot_follows_dribble            28 non-null       object \n",
      " 90  pass_no_touch                   615 non-null      object \n",
      " 91  dribble_no_touch                99 non-null       object \n",
      " 92  half_start_late_video_start     48 non-null       object \n",
      " 93  player_off_permanent            8 non-null        object \n",
      " 94  half_end_early_video_end        8 non-null        object \n",
      "dtypes: float64(27), int64(13), object(55)\n",
      "memory usage: 2.3+ GB\n"
     ]
    }
   ],
   "source": [
    "if len(event_links) == 0:\n",
    "    print('No update')\n",
    "else:\n",
    "    if UPDATE_FILES:\n",
    "        df_event = update(DATA_FOLDER, 'event', ids_to_update)\n",
    "        df_event.to_parquet(os.path.join(DATA_FOLDER, 'event.parquet'))\n",
    "        df_event.info(verbose=True, null_counts=True)\n",
    "    else:\n",
    "        df_event = pd.concat([pd.read_parquet(file) for file in event_files])\n",
    "        df_event.to_parquet(os.path.join(DATA_FOLDER, 'event.parquet'))\n",
    "        df_event.info(verbose=True, null_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get shot freeze frames files as a single dataframe and save to parquet.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 277829 entries, 0 to 341\n",
      "Data columns (total 10 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   id                    277829 non-null  object \n",
      " 1   event_freeze_id       277829 non-null  int64  \n",
      " 2   player_teammate       277829 non-null  bool   \n",
      " 3   player_id             277829 non-null  int64  \n",
      " 4   player_name           277829 non-null  object \n",
      " 5   player_position_id    277829 non-null  int64  \n",
      " 6   player_position_name  277829 non-null  object \n",
      " 7   x                     277829 non-null  float64\n",
      " 8   y                     277829 non-null  float64\n",
      " 9   match_id              277829 non-null  int64  \n",
      "dtypes: bool(1), float64(2), int64(4), object(3)\n",
      "memory usage: 21.5+ MB\n"
     ]
    }
   ],
   "source": [
    "if len(event_links) == 0:\n",
    "    print('No update')\n",
    "else:\n",
    "    if UPDATE_FILES:\n",
    "        df_freeze = update(DATA_FOLDER, 'freeze', ids_to_update)\n",
    "        df_freeze.to_parquet(os.path.join(DATA_FOLDER, 'freeze.parquet'))\n",
    "        df_freeze.info(verbose=True, null_counts=True)\n",
    "    else:\n",
    "        freeze_files = glob.glob(os.path.join(DATA_FOLDER, 'freeze_raw', '*.parquet'))\n",
    "        df_freeze = pd.concat([pd.read_parquet(file) for file in freeze_files])\n",
    "        df_freeze.to_parquet(os.path.join(DATA_FOLDER, 'freeze.parquet'))\n",
    "        df_freeze.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get tactics files as a single dataframe and save to parquet.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 36817 entries, 0 to 32\n",
      "Data columns (total 8 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   id                    36817 non-null  object\n",
      " 1   event_tactics_id      36817 non-null  int64 \n",
      " 2   player_jersey_number  36817 non-null  int64 \n",
      " 3   player_id             36817 non-null  int64 \n",
      " 4   player_name           36817 non-null  object\n",
      " 5   player_position_id    36817 non-null  int64 \n",
      " 6   player_position_name  36817 non-null  object\n",
      " 7   match_id              36817 non-null  int64 \n",
      "dtypes: int64(5), object(3)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "if len(event_links) == 0:\n",
    "    print('No update')\n",
    "else:\n",
    "    if UPDATE_FILES:\n",
    "        df_tactic = update(DATA_FOLDER, 'tactic', ids_to_update)\n",
    "        df_tactic.to_parquet(os.path.join(DATA_FOLDER, 'tactic.parquet'))\n",
    "        df_tactic.info(verbose=True, null_counts=True)\n",
    "    else:\n",
    "        tactic_files = glob.glob(os.path.join(DATA_FOLDER, 'tactic_raw', '*.parquet'))\n",
    "        df_tactic = pd.concat([pd.read_parquet(file) for file in tactic_files])\n",
    "        df_tactic.to_parquet(os.path.join(DATA_FOLDER, 'tactic.parquet'))\n",
    "        df_tactic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get related events files as a single dataframe and save to parquet.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-42-fb457d88fc62>:12: FutureWarning: null_counts is deprecated. Use show_counts instead\n",
      "  df_related.info(verbose=True, null_counts=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6219794 entries, 0 to 7467\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count    Dtype \n",
      "---  ------             --------------    ----- \n",
      " 0   id                 6219794 non-null  object\n",
      " 1   id_related         6219794 non-null  object\n",
      " 2   type_name          6219794 non-null  object\n",
      " 3   index              6219794 non-null  int64 \n",
      " 4   type_name_related  6219794 non-null  object\n",
      " 5   index_related      6219794 non-null  int64 \n",
      " 6   match_id           6219794 non-null  int64 \n",
      "dtypes: int64(3), object(4)\n",
      "memory usage: 379.6+ MB\n"
     ]
    }
   ],
   "source": [
    "if len(event_links) == 0:\n",
    "    print('No update')\n",
    "else:\n",
    "    if UPDATE_FILES:\n",
    "        df_related = update(DATA_FOLDER, 'related', ids_to_update)\n",
    "        df_related.to_parquet(os.path.join(DATA_FOLDER, 'related.parquet'))\n",
    "        df_related.info(verbose=True, null_counts=True)\n",
    "    else:\n",
    "        related_files = glob.glob(os.path.join(DATA_FOLDER, 'related_raw', '*.parquet'))\n",
    "        df_related = pd.concat([pd.read_parquet(file) for file in related_files])\n",
    "        df_related.to_parquet(os.path.join(DATA_FOLDER, 'related.parquet'))\n",
    "        df_related.info(verbose=True, null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
